{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\mask_repo\\Mask_RCNN-master\\Mask_RCNN-master\n"
     ]
    }
   ],
   "source": [
    "%cd E:\\mask_repo\\Mask_RCNN-master\\Mask_RCNN-master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"E:\\mask_repo\\Mask_RCNN-master\\Mask_RCNN-master\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     8\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 8\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_META_SIZE                16\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ShapesConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"shapes\"\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 8\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 3  # background + 3 shapes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 128\n",
    "    IMAGE_MAX_DIM = 128\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 5\n",
    "    \n",
    "config = ShapesConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapesDataset(utils.Dataset):\n",
    "    \"\"\"Generates the shapes synthetic dataset. The dataset consists of simple\n",
    "    shapes (triangles, squares, circles) placed randomly on a blank surface.\n",
    "    The images are generated on the fly. No file access required.\n",
    "    \"\"\"\n",
    "\n",
    "    def load_shapes(self, count, height, width):\n",
    "        \"\"\"Generate the requested number of synthetic images.\n",
    "        count: number of images to generate.\n",
    "        height, width: the size of the generated images.\n",
    "        \"\"\"\n",
    "        # Add classes\n",
    "        self.add_class(\"shapes\", 1, \"square\")\n",
    "        self.add_class(\"shapes\", 2, \"circle\")\n",
    "        self.add_class(\"shapes\", 3, \"triangle\")\n",
    "\n",
    "        # Add images\n",
    "        # Generate random specifications of images (i.e. color and\n",
    "        # list of shapes sizes and locations). This is more compact than\n",
    "        # actual images. Images are generated on the fly in load_image().\n",
    "        for i in range(count):\n",
    "            bg_color, shapes = self.random_image(height, width)\n",
    "            self.add_image(\"shapes\", image_id=i, path=None,\n",
    "                           width=width, height=height,\n",
    "                           bg_color=bg_color, shapes=shapes)\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        \"\"\"Generate an image from the specs of the given image ID.\n",
    "        Typically this function loads the image from a file, but\n",
    "        in this case it generates the image on the fly from the\n",
    "        specs in image_info.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        bg_color = np.array(info['bg_color']).reshape([1, 1, 3])\n",
    "        image = np.ones([info['height'], info['width'], 3], dtype=np.uint8)\n",
    "        image = image * bg_color.astype(np.uint8)\n",
    "        for shape, color, dims in info['shapes']:\n",
    "            image = self.draw_shape(image, shape, dims, color)\n",
    "        return image\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the shapes data of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"shapes\":\n",
    "            return info[\"shapes\"]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for shapes of the given image ID.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        shapes = info['shapes']\n",
    "        count = len(shapes)\n",
    "        mask = np.zeros([info['height'], info['width'], count], dtype=np.uint8)\n",
    "        for i, (shape, _, dims) in enumerate(info['shapes']):\n",
    "            mask[:, :, i:i+1] = self.draw_shape(mask[:, :, i:i+1].copy(),\n",
    "                                                shape, dims, 1)\n",
    "        # Handle occlusions\n",
    "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "        for i in range(count-2, -1, -1):\n",
    "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
    "        # Map class names to class IDs.\n",
    "        class_ids = np.array([self.class_names.index(s[0]) for s in shapes])\n",
    "        return mask.astype(np.bool), class_ids.astype(np.int32)\n",
    "\n",
    "    def draw_shape(self, image, shape, dims, color):\n",
    "        \"\"\"Draws a shape from the given specs.\"\"\"\n",
    "        # Get the center x, y and the size s\n",
    "        x, y, s = dims\n",
    "        if shape == 'square':\n",
    "            cv2.rectangle(image, (x-s, y-s), (x+s, y+s), color, -1)\n",
    "        elif shape == \"circle\":\n",
    "            cv2.circle(image, (x, y), s, color, -1)\n",
    "        elif shape == \"triangle\":\n",
    "            points = np.array([[(x, y-s),\n",
    "                                (x-s/math.sin(math.radians(60)), y+s),\n",
    "                                (x+s/math.sin(math.radians(60)), y+s),\n",
    "                                ]], dtype=np.int32)\n",
    "            cv2.fillPoly(image, points, color)\n",
    "        return image\n",
    "\n",
    "    def random_shape(self, height, width):\n",
    "        \"\"\"Generates specifications of a random shape that lies within\n",
    "        the given height and width boundaries.\n",
    "        Returns a tuple of three valus:\n",
    "        * The shape name (square, circle, ...)\n",
    "        * Shape color: a tuple of 3 values, RGB.\n",
    "        * Shape dimensions: A tuple of values that define the shape size\n",
    "                            and location. Differs per shape type.\n",
    "        \"\"\"\n",
    "        # Shape\n",
    "        shape = random.choice([\"square\", \"circle\", \"triangle\"])\n",
    "        # Color\n",
    "        color = tuple([random.randint(0, 255) for _ in range(3)])\n",
    "        # Center x, y\n",
    "        buffer = 20\n",
    "        y = random.randint(buffer, height - buffer - 1)\n",
    "        x = random.randint(buffer, width - buffer - 1)\n",
    "        # Size\n",
    "        s = random.randint(buffer, height//4)\n",
    "        return shape, color, (x, y, s)\n",
    "\n",
    "    def random_image(self, height, width):\n",
    "        \"\"\"Creates random specifications of an image with multiple shapes.\n",
    "        Returns the background color of the image and a list of shape\n",
    "        specifications that can be used to draw the image.\n",
    "        \"\"\"\n",
    "        # Pick random background color\n",
    "        bg_color = np.array([random.randint(0, 255) for _ in range(3)])\n",
    "        # Generate a few random shapes and record their\n",
    "        # bounding boxes\n",
    "        shapes = []\n",
    "        boxes = []\n",
    "        N = random.randint(1, 4)\n",
    "        for _ in range(N):\n",
    "            shape, color, dims = self.random_shape(height, width)\n",
    "            shapes.append((shape, color, dims))\n",
    "            x, y, s = dims\n",
    "            boxes.append([y-s, x-s, y+s, x+s])\n",
    "        # Apply non-max suppression wit 0.3 threshold to avoid\n",
    "        # shapes covering each other\n",
    "        keep_ixs = utils.non_max_suppression(np.array(boxes), np.arange(N), 0.3)\n",
    "        shapes = [s for i, s in enumerate(shapes) if i in keep_ixs]\n",
    "        return bg_color, shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "dataset_train = ShapesDataset()\n",
    "dataset_train.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation dataset\n",
    "dataset_val = ShapesDataset()\n",
    "dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxAAAACWCAYAAABO+G6lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAIeUlEQVR4nO3daahtdRnH8d9jikgFGVFGvQgrK31RUjYPFonNSRMFzQVFGY1EE2QzSVGBzYONUNBwk0oMs6xrmqFBE2Q2vSjrZoNNdit9erHXpcPleu+jednncj4fOJy91lln7f++/F/s7/6vdW51dwAAACYOWvcAAACAA4eAAAAAxgQEAAAwJiAAAIAxAQEAAIwJCAAAYGztAVFVt6mqs3fbd+l1OM+ZVXXs8vhhVfXHqqpl+9SqesrgHG+oql9tHE9VHVtV51XVN6vqnKo6ctl/5LLvG1X19aq69V7Oe9uquqiq/lZV992w/51VdcHy9YoN+19ZVd+tqgur6iXX9t8CAAD2l7UHxPVoe5L7LI/vk+TiJMds2P7W4BzvSfLA3fZdluQh3X3/JG9L8rpl//OSfLi7j0/ysSQv2Mt5L0tyQpLP7rb/3d19zyT3TvLoJTRunOSZSXbtf25V3XAwdragqrrBuscAAGwtB0xAVNV7q+qpVXVQVZ1VVffY7ZDtSXZ9un/nJO9Nct+qOjTJEd39y309R3dfluTq3fb9trv/umz+K8l/lsc/SnKT5fFNk+yoqkOrantV3bGqbrGsINyku//R3X/cw/P9dPl+dZKrlq8rk/wmyWHL15VJ/r2vsbM5VdUxVXX+skp1ZlUdvcyLL1fVx6vqlOW4Szf8zoeq6vjl8VnLKteFVXWvZd8pVfXRqjojyROq6gFVde5y3Pt2rbwBAOwPB697AIu7VtU39nHMi5Ock9Vqwte6+zu7/fw7ST5SVYck6STfTPL2JD9McmGSLG/A3rKHc7++u8/Z25MvqwBvSvKMZdfZSc6qqmclOTTJ3bt7Z1U9M8lHk1yR5EXd/ed9vK4sl1f9bFfkVNVXkvwkq8B7Y3f/a1/nYNM6Mcnp3f2BqjooyReSvLC7z6+qDw5+/zHd/fequlOSdyd50LJ/Z3c/aomFi5Mc391XVNU7kjw8yZf2w2sBANg0AXFRdz9418ae7oHo7n9W1elJTk1yy2v4+Y4kj0nyve7+fVUdkdWqxPblmPOTHH9tB7dEyWeSvKW7f7zsfmuS13T356vqSUnenOT53X1JVf0iyU27+9uDcz84ydOSPHLZPirJY5McmVVAnFtV27r719d23GwKpyd5dVV9Ksn3k9w+S9BmFb17undm1707hyV5V1XdIavVqVttOGbX3LpZktsk+eKy8HCjrOIT/i9VdXKSxyW5tLufve7xsDWZh6ybObhnmyUg9qmqbpnkWUnemNWb9T3dXLw9ycuTvGrZ/k2Sx2dZNbguKxDLp8afTLKtu7dt/FGSy5fHO7K6jClVdUKSQ5JcXlWP6u4z9vKa7pHkDUke2t1XbjjvX7t753LMzqzeFHJg2tndL0uS5eb83yW5W1bxcFxW98ckyRXLHN+R5C5JPpHkIUmu6u77VdXRSTbOpauW75cn+XmSR3T335bnOWT/viS2gu4+Lclp6x4HW5t5yLqZg3t2QATE8ib+9KwuCbqgqj5dVQ/v7i/vdui3sgqLC5bt85KclNVlTPtcgVgq84lJ7rS82XtOkmOzuiTkFlX15CQ/6O4XZBUy76+q/2QVDM+pqptndZnTiVndK3F2VV2c5C9JPp/k6CTHVNVXuvu1ST68PPW25dPjl3b3Rcv17hdkFRNf726fKB+4nlRVT8/qsrrfZjVvPlRVf8j/AjRZrax9Nat7a3Ys+85P8splLp63p5N3dy9/qeuM5XKmq7O63O/7++G1AACkunvdY4AtaQnS23X3KeseCwDA1AHzV5gAAID1swIBAACMWYEAAADGBAQAADC217/C9PKfPdb1TVvIqbf93Kb8H4wPO/Zk83ALufJ7p226eWgObi2bcQ4m5uFWYx6yGVzTPLQCAQAAjAkIAABgTEAAAABjAgIAABgTEAAAwJiAAAAAxgQEAAAwJiAAAIAxAQEAAIwJCAAAYExAAAAAYwICAAAYExAAAMCYgAAAAMYEBAAAMCYgAACAMQEBAACMCQgAAGBMQAAAAGMCAgAAGBMQAADAmIAAAADGBAQAADAmIAAAgDEBAQAAjAkIAABgTEAAAABjAgIAABgTEAAAwJiAAAAAxgQEAAAwJiAAAIAxAQEAAIwJCAAAYExAAAAAYwICAAAYExAAAMCYgAAAAMYEBAAAMCYgAACAMQEBAACMCQgAAGDs4HUP4Pp21EO3rXsIa3PJmSetewgs/vTd09Y9hLU5/LiT1z0EAGA/sgIBAACMCQgAAGBMQAAAAGMCAgAAGBMQAADAmIAAAADGBAQAADAmIAAAgDEBAQAAjAkIAABgTEAAAABjAgIAABgTEAAAwJiAAAAAxgQEAAAwJiAAAIAxAQEAAIwJCAAAYExAAAAAYwICAAAYExAAAMCYgAAAAMYEBAAAMCYgAACAMQEBAACMCQgAAGBMQAAAAGMCAgAAGBMQAADAmIAAAADGBAQAADAmIAAAgDEBAQAAjAkIAABgTEAAAABjAgIAABgTEAAAwJiAAAAAxgQEAAAwJiAAAIAxAQEAAIwJCAAAYExAAAAAYwICAAAYExAAAMCYgAAAAMYEBAAAMCYgAACAMQEBAACMCQgAAGBMQAAAAGMCAgAAGBMQAADAmIAAAADGBAQAADAmIAAAgDEBAQAAjAkIAABgTEAAAABjAgIAABgTEAAAwJiAAAAAxg5e9wCub5ecedK6hwA5/LiT1z0EAID9wgoEAAAwJiAAAIAxAQEAAIwJCAAAYExAAAAAYwICAAAYExAAAMCYgAAAAMYEBAAAMCYgAACAMQEBAACMCQgAAGBMQAAAAGMCAgAAGBMQAADAmIAAAADGBAQAADBW3b3uMQAAAAcIKxAAAMCYgAAAAMYEBAAAMCYgAACAMQEBAACMCQgAAGDsvzALrgyGOUyrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
