{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential,Model,load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import BatchNormalization, Lambda, Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "import numpy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_net(num_classes):\n",
    "    # placeholder for input image\n",
    "    input_image = Input(shape=(227,227,3))\n",
    "    # ============================================= TOP BRANCH ===================================================\n",
    "    # first top convolution layer\n",
    "    top_conv1 = Convolution2D(filters=48,kernel_size=(11,11),strides=(4,4),\n",
    "                              input_shape=(227,227,3),activation='relu')(input_image)\n",
    "    top_conv1 = BatchNormalization()(top_conv1)\n",
    "    top_conv1 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_conv1)\n",
    "\n",
    "    # second top convolution layer\n",
    "    # split feature map by half\n",
    "    top_top_conv2 = Lambda(lambda x : x[:,:,:,:24])(top_conv1)\n",
    "    top_bot_conv2 = Lambda(lambda x : x[:,:,:,24:])(top_conv1)\n",
    "\n",
    "    top_top_conv2 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_top_conv2)\n",
    "    top_top_conv2 = BatchNormalization()(top_top_conv2)\n",
    "    top_top_conv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_top_conv2)\n",
    "\n",
    "    top_bot_conv2 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_bot_conv2)\n",
    "    top_bot_conv2 = BatchNormalization()(top_bot_conv2)\n",
    "    top_bot_conv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_bot_conv2)\n",
    "\n",
    "    # third top convolution layer\n",
    "    # concat 2 feature map\n",
    "    top_conv3 = Concatenate()([top_top_conv2,top_bot_conv2])\n",
    "    top_conv3 = Convolution2D(filters=192,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_conv3)\n",
    "\n",
    "    # fourth top convolution layer\n",
    "    # split feature map by half\n",
    "    top_top_conv4 = Lambda(lambda x : x[:,:,:,:96])(top_conv3)\n",
    "    top_bot_conv4 = Lambda(lambda x : x[:,:,:,96:])(top_conv3)\n",
    "\n",
    "    top_top_conv4 = Convolution2D(filters=96,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_top_conv4)\n",
    "    top_bot_conv4 = Convolution2D(filters=96,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_bot_conv4)\n",
    "\n",
    "    # fifth top convolution layer\n",
    "    top_top_conv5 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_top_conv4)\n",
    "    top_top_conv5 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_top_conv5) \n",
    "\n",
    "    top_bot_conv5 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_bot_conv4)\n",
    "    top_bot_conv5 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_bot_conv5)\n",
    "    \n",
    "        # ============================================= TOP BOTTOM ===================================================\n",
    "    # first bottom convolution layer\n",
    "    bottom_conv1 = Convolution2D(filters=48,kernel_size=(11,11),strides=(4,4),\n",
    "                              input_shape=(227,227,3),activation='relu')(input_image)\n",
    "    bottom_conv1 = BatchNormalization()(bottom_conv1)\n",
    "    bottom_conv1 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_conv1)\n",
    "\n",
    "    # second bottom convolution layer\n",
    "    # split feature map by half\n",
    "    bottom_top_conv2 = Lambda(lambda x : x[:,:,:,:24])(bottom_conv1)\n",
    "    bottom_bot_conv2 = Lambda(lambda x : x[:,:,:,24:])(bottom_conv1)\n",
    "\n",
    "    bottom_top_conv2 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_top_conv2)\n",
    "    bottom_top_conv2 = BatchNormalization()(bottom_top_conv2)\n",
    "    bottom_top_conv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_top_conv2)\n",
    "\n",
    "    bottom_bot_conv2 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_bot_conv2)\n",
    "    bottom_bot_conv2 = BatchNormalization()(bottom_bot_conv2)\n",
    "    bottom_bot_conv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_bot_conv2)\n",
    "\n",
    "    # third bottom convolution layer\n",
    "    # concat 2 feature map\n",
    "    bottom_conv3 = Concatenate()([bottom_top_conv2,bottom_bot_conv2])\n",
    "    bottom_conv3 = Convolution2D(filters=192,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_conv3)\n",
    "\n",
    "    # fourth bottom convolution layer\n",
    "    # split feature map by half\n",
    "    bottom_top_conv4 = Lambda(lambda x : x[:,:,:,:96])(bottom_conv3)\n",
    "    bottom_bot_conv4 = Lambda(lambda x : x[:,:,:,96:])(bottom_conv3)\n",
    "\n",
    "    bottom_top_conv4 = Convolution2D(filters=96,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_top_conv4)\n",
    "    bottom_bot_conv4 = Convolution2D(filters=96,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_bot_conv4)\n",
    "\n",
    "    # fifth bottom convolution layer\n",
    "    bottom_top_conv5 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_top_conv4)\n",
    "    bottom_top_conv5 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_top_conv5) \n",
    "\n",
    "    bottom_bot_conv5 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_bot_conv4)\n",
    "    bottom_bot_conv5 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_bot_conv5)\n",
    "\n",
    "    # ======================================== CONCATENATE TOP AND BOTTOM BRANCH =================================\n",
    "    conv_output = Concatenate()([top_top_conv5,top_bot_conv5,bottom_top_conv5,bottom_bot_conv5])\n",
    "\n",
    "    # Flatten\n",
    "    flatten = Flatten()(conv_output)\n",
    "\n",
    "    # Fully-connected layer\n",
    "    FC_1 = Dense(units=4096, activation='relu')(flatten)\n",
    "    FC_1 = Dropout(0.6)(FC_1)\n",
    "    FC_2 = Dense(units=4096, activation='relu')(FC_1)\n",
    "    FC_2 = Dropout(0.6)(FC_2)\n",
    "    output = Dense(units=num_classes, activation='softmax')(FC_2)\n",
    "    \n",
    "    model = Model(inputs=input_image,outputs=output)\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    # sgd = SGD(lr=0.01, momentum=0.9, decay=0.0005, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 92 images belonging to 4 classes.\n",
      "Found 17 images belonging to 4 classes.\n",
      "Epoch 1/5\n",
      "12/12 [==============================] - 130s 11s/step - loss: 0.8976 - acc: 0.6654 - val_loss: 0.1190 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 1.00000, saving model to color_weights.hdf5\n",
      "Epoch 2/5\n",
      "12/12 [==============================] - 117s 10s/step - loss: 0.1410 - acc: 0.9728 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 1.00000\n",
      "Epoch 3/5\n",
      "12/12 [==============================] - 120s 10s/step - loss: 0.0215 - acc: 1.0000 - val_loss: 8.6060e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 1.00000\n",
      "Epoch 4/5\n",
      "12/12 [==============================] - 117s 10s/step - loss: 0.0262 - acc: 0.9892 - val_loss: 5.5883e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 1.00000\n",
      "Epoch 5/5\n",
      "12/12 [==============================] - 119s 10s/step - loss: 0.0132 - acc: 0.9974 - val_loss: 0.2799 - val_acc: 0.7647\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 1.00000\n"
     ]
    }
   ],
   "source": [
    "img_rows , img_cols = 227,227\n",
    "num_classes = 4\n",
    "batch_size = 32\n",
    "nb_epoch = 5\n",
    "\n",
    "# initialise model\n",
    "model = color_net(num_classes)\n",
    "\n",
    "filepath = 'color_weights.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.3,\n",
    "        horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "            'train/',\n",
    "            target_size=(img_rows, img_cols),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "            'test/',\n",
    "            target_size=(img_rows, img_cols),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "\n",
    "model.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=12,\n",
    "        epochs=nb_epoch,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=30,\n",
    "        callbacks=callbacks_list)\n",
    "\n",
    "model.save('color_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load weights into new model\n",
    "loaded_model.load_weights(\"color_model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-7c90bccfd1de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# evaluate loaded model on test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjpg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s: %.2f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(image.jpg)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'C:/Users/user/test/green',\n",
    "        \n",
    "        color_mode=\"rgb\",\n",
    "        shuffle = False,\n",
    "        class_mode='categorical',\n",
    "        batch_size=1)\n",
    "\n",
    "filenames = test_generator.filenames\n",
    "nb_samples = len(filenames)\n",
    "\n",
    "predict = model.predict_generator(test_generator,steps = nb_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
